# torchrun --nproc_per_node 1 --master_addr localhost --master_port 6000  ./hstu/pretrain_gr_ranking.py --gin-config-file examples/hstu/movielen_ranking.gin 
TrainerArgs.train_batch_size = 128
TrainerArgs.eval_batch_size = 128
TrainerArgs.eval_interval = 100
TrainerArgs.log_interval = 100
TrainerArgs.seed = 1234
TrainerArgs.max_train_iters = 1000
TrainerArgs.profile = True
TrainerArgs.pipeline_type = "prefetch"
TrainerArgs.enable_balanced_shuffler = True  # Set to True to enable balanced batch shuffling

# ml-1m : 5 contextual features, 
# ml-20m : 1 contextual feature
DatasetArgs.dataset_name = 'ml-20m'
# seqlen for attention is 
# contextual + (history + candidate) * 2
DatasetArgs.max_history_seqlen = 200
DatasetArgs.shuffle = False
DatasetArgs.max_num_candidates = 20

NetworkArgs.dtype_str = "bfloat16"
NetworkArgs.num_layers = 1
NetworkArgs.num_attention_heads = 4
NetworkArgs.hidden_size = 128
NetworkArgs.kv_channels = 128
NetworkArgs.target_group_size = 1

# ml-20m ratings 1:0.5:5
# ml-1m ratings 1:1:5
RankingArgs.prediction_head_arch = [512, 10]
RankingArgs.prediction_head_bias = True
RankingArgs.num_tasks = 1
RankingArgs.eval_metrics = ("AUC",)

OptimizerArgs.optimizer_str = 'adam'
OptimizerArgs.learning_rate = 1e-3
OptimizerArgs.adam_beta1 = 0.9
OptimizerArgs.adam_beta2 = 0.98

TensorModelParallelArgs.tensor_model_parallel_size = 1